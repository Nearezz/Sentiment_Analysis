{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "83000dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/indranili/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Import Libraries & Load Data ---------------------------------------\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "nltk.download('stopwords', download_dir='/Users/indranili/nltk_data')\n",
    "\n",
    "tweets_df = pd.read_csv(\"../data/filtered_stocks_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e6861a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweet_id', 'date', 'stock_ticker', 'text', 'user_followers', 'user_screen_name', 'user_verified', 'word_count', 'caps_ratio', 'has_url', 'emoji_count', 'cashtag_count', 'total_engagement', 'is_retweet', 'original_author', 'original_retweets', 'original_favorites', 'current_retweets', 'current_favorites', 'text_cleaned']\n",
      "             tweet_id        date stock_ticker  \\\n",
      "0  459825460810383360  2014-04-26            V   \n",
      "1  459827071418925056  2014-04-26            V   \n",
      "2  459977378496667648  2014-04-26            V   \n",
      "3  459994705191632896  2014-04-26            V   \n",
      "4  459996785579028480  2014-04-26            V   \n",
      "\n",
      "                                                text  user_followers  \\\n",
      "0  RT @philstockworld: Yesterday's Featured $AAPL...          459556   \n",
      "1  RT @philstockworld: Yesterday's Featured $AAPL...          459554   \n",
      "2  RT @philstockworld: Yesterday's Featured $AAPL...          459595   \n",
      "3  RT @philstockworld: Yesterday's Featured $AAPL...          459590   \n",
      "4  RT @philstockworld: Yesterday's Featured $AAPL...          459591   \n",
      "\n",
      "  user_screen_name  user_verified  word_count  caps_ratio  has_url  \\\n",
      "0   philstockworld          False          25        0.08        0   \n",
      "1   philstockworld          False          25        0.08        0   \n",
      "2   philstockworld          False          25        0.08        0   \n",
      "3   philstockworld          False          25        0.08        0   \n",
      "4   philstockworld          False          25        0.08        0   \n",
      "\n",
      "   emoji_count  cashtag_count  total_engagement  is_retweet original_author  \\\n",
      "0            0              3               767        True  philstockworld   \n",
      "1            0              3               774        True  philstockworld   \n",
      "2            0              3              1694        True  philstockworld   \n",
      "3            0              3              1874        True  philstockworld   \n",
      "4            0              3              1905        True  philstockworld   \n",
      "\n",
      "   original_retweets  original_favorites  current_retweets  current_favorites  \\\n",
      "0                760                   7                 0                  0   \n",
      "1                767                   7                 0                  0   \n",
      "2               1374                 320                 0                  0   \n",
      "3               1449                 425                 0                  0   \n",
      "4               1461                 444                 0                  0   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  RT : Yesterdays Featured $AAPL Trade is Up 24 ...  \n",
      "1  RT : Yesterdays Featured $AAPL Trade is Up 24 ...  \n",
      "2  RT : Yesterdays Featured $AAPL Trade is Up 24 ...  \n",
      "3  RT : Yesterdays Featured $AAPL Trade is Up 24 ...  \n",
      "4  RT : Yesterdays Featured $AAPL Trade is Up 24 ...  \n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.columns.tolist())\n",
    "print(tweets_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "474f76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['date'] = pd.to_datetime(tweets_df['date']).dt.date\n",
    "\n",
    "\n",
    "tweets_df['vader'] = tweets_df['text_cleaned'].apply(\n",
    "    lambda x: analyzer.polarity_scores(str(x))['compound']\n",
    ")\n",
    "\n",
    "daily = (\n",
    "    tweets_df\n",
    "    .groupby(['stock_ticker', 'date'])\n",
    "    .agg(\n",
    "        avg_vader    = ('vader', 'mean'),\n",
    "        std_vader    = ('vader', 'std'),\n",
    "        tweet_count  = ('text', 'count'),\n",
    "        avg_length   = ('text', lambda x: x.str.len().mean())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ed3998e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BBL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CELG']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CHL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['FB']: YFPricesMissingError('possibly delisted; no price data found  (1d 2014-01-02 -> 2016-03-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1388638800, endDate = 1459396800\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TOT']: YFPricesMissingError('possibly delisted; no price data found  (1d 2014-01-02 -> 2016-03-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1388638800, endDate = 1459396800\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_date = tweets_df['date'].min().strftime('%Y-%m-%d')\n",
    "end_date   = tweets_df['date'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "symbols = daily['stock_ticker'].unique()\n",
    "price_list = []\n",
    "\n",
    "for sym in symbols:\n",
    "    dfp = yf.download(sym, start=start_date, end=end_date, auto_adjust=True)\n",
    "\n",
    "    # ---- FORCE FLATTEN MULTIINDEX ----\n",
    "    dfp.columns = dfp.columns.get_level_values(0)\n",
    "\n",
    "    # now dfp has: Open, High, Low, Close, Volume\n",
    "    dfp = dfp[['Close']]\n",
    "    dfp['return'] = dfp['Close'].pct_change()\n",
    "    dfp['stock_ticker'] = sym\n",
    "    dfp['date'] = dfp.index.date\n",
    "    price_list.append(dfp)\n",
    "\n",
    "price_df = pd.concat(price_list).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "94544b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (242, 23)\n",
      "\n",
      "==============================\n",
      "Evaluating horizon: target_5d\n",
      "==============================\n",
      "Elastic Net R²: 0.0223918552938992\n",
      "LR (selected) R²: -0.008004206817759929\n",
      "Random Forest R²: 0.034611174593545346\n",
      "HGB R²: -0.05083219838959363\n",
      "\n",
      "==============================\n",
      "Evaluating horizon: target_10d\n",
      "==============================\n",
      "Elastic Net R²: -0.42769813614671315\n",
      "LR (selected) R²: -0.44623893679267046\n",
      "Random Forest R²: -0.1717585827664212\n",
      "HGB R²: -0.3725153978031084\n",
      "\n",
      "==============================\n",
      "Evaluating horizon: target_20d\n",
      "==============================\n",
      "Elastic Net R²: -0.5799568294339654\n",
      "LR (selected) R²: -0.6361190966933363\n",
      "Random Forest R²: -0.560462272173941\n",
      "HGB R²: -0.5860664528761528\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# FULL PIPELINE FOR MULTI-HORIZON RETURNS (5D, 10D, 20D)\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. MERGE TWEET FEATURES + PRICE DATA\n",
    "# ============================================================\n",
    "merged = pd.merge(\n",
    "    daily,\n",
    "    price_df[['stock_ticker', 'date', 'Close', 'return']],\n",
    "    on=['stock_ticker', 'date'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. TARGET HORIZONS: 5D, 10D, 20D FUTURE RETURNS\n",
    "# ============================================================\n",
    "merged['target_5d'] = merged.groupby('stock_ticker')['Close'].pct_change(-5)\n",
    "merged['target_10d'] = merged.groupby('stock_ticker')['Close'].pct_change(-10)\n",
    "merged['target_20d'] = merged.groupby('stock_ticker')['Close'].pct_change(-20)\n",
    "\n",
    "# ============================================================\n",
    "# 3. MOMENTUM FEATURES (past returns)\n",
    "# ============================================================\n",
    "merged['mom_5d'] = merged.groupby('stock_ticker')['Close'].pct_change(5)\n",
    "merged['mom_10d'] = merged.groupby('stock_ticker')['Close'].pct_change(10)\n",
    "merged['mom_20d'] = merged.groupby('stock_ticker')['Close'].pct_change(20)\n",
    "\n",
    "# 1-day momentum (baseline)\n",
    "merged['prev_return_1'] = merged.groupby('stock_ticker')['return'].shift(1)\n",
    "\n",
    "# ============================================================\n",
    "# 4. SENTIMENT EWMA (captures sentiment trends)\n",
    "# ============================================================\n",
    "merged['sent_ewma'] = (\n",
    "    merged.groupby('stock_ticker')['avg_vader']\n",
    "          .transform(lambda x: x.ewm(alpha=0.3).mean())\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5. VOLATILITY FEATURES\n",
    "# ============================================================\n",
    "merged['vol_5'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(5).std())\n",
    "merged['vol_10'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(10).std())\n",
    "merged['vol_20'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(20).std())\n",
    "\n",
    "# Mean return features\n",
    "merged['mean_ret_5'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(5).mean())\n",
    "merged['mean_ret_10'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(10).mean())\n",
    "merged['mean_ret_20'] = merged.groupby('stock_ticker')['return'].transform(lambda x: x.rolling(20).mean())\n",
    "\n",
    "# ============================================================\n",
    "# 6. PRICE RANGE VOLATILITY\n",
    "# ============================================================\n",
    "merged['range_vol'] = (\n",
    "    merged.groupby('stock_ticker')['Close']\n",
    "          .transform(lambda x: (x - x.rolling(5).min()) / x.rolling(5).min())\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7. CLEAN UP DATA\n",
    "# ============================================================\n",
    "merged['std_vader'] = merged['std_vader'].fillna(0)\n",
    "\n",
    "merged = merged.dropna(subset=[\n",
    "    'mom_5d', 'mom_10d', 'mom_20d',\n",
    "    'vol_5', 'vol_10', 'vol_20',\n",
    "    'mean_ret_5', 'mean_ret_10', 'mean_ret_20',\n",
    "    'range_vol',\n",
    "    'target_5d', 'target_10d', 'target_20d'\n",
    "])\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 8. FEATURE MATRIX\n",
    "# ============================================================\n",
    "feature_cols = [\n",
    "    'avg_vader', 'std_vader', 'tweet_count', 'avg_length', 'sent_ewma',\n",
    "\n",
    "    # Momentum\n",
    "    'prev_return_1',\n",
    "    'mom_5d', 'mom_10d', 'mom_20d',\n",
    "\n",
    "    # Volatility\n",
    "    'vol_5', 'vol_10', 'vol_20',\n",
    "\n",
    "    # Trend\n",
    "    'mean_ret_5', 'mean_ret_10', 'mean_ret_20',\n",
    "\n",
    "    # Range volatility\n",
    "    'range_vol'\n",
    "]\n",
    "\n",
    "X = merged[feature_cols]\n",
    "\n",
    "# ============================================================\n",
    "# FUNCTION: Evaluate model for given target horizon\n",
    "# ============================================================\n",
    "def evaluate_horizon(target):\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Evaluating horizon: {target}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    y = merged[target]\n",
    "\n",
    "    # Time split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "    # ---- Elastic Net ----\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    enet = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=5000)\n",
    "    enet.fit(X_train_scaled, y_train)\n",
    "    print(\"Elastic Net R²:\", enet.score(X_test_scaled, y_test))\n",
    "\n",
    "    # ---- EN → LR ----\n",
    "    coefs = pd.Series(enet.coef_, index=X.columns)\n",
    "    selected = list(coefs[coefs != 0].index)\n",
    "    if len(selected) == 0:\n",
    "        selected = X.columns\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[selected], y_train)\n",
    "    print(\"LR (selected) R²:\", lr.score(X_test[selected], y_test))\n",
    "\n",
    "    # ---- Random Forest ----\n",
    "    rf = RandomForestRegressor(n_estimators=400, max_depth=8, min_samples_leaf=20)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Random Forest R²:\", rf.score(X_test, y_test))\n",
    "\n",
    "    # ---- HGB ----\n",
    "    hgb = HistGradientBoostingRegressor(max_depth=5, learning_rate=0.05, max_leaf_nodes=31)\n",
    "    hgb.fit(X_train, y_train)\n",
    "    print(\"HGB R²:\", hgb.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. Evaluate all horizons (this is the main output)\n",
    "# ============================================================\n",
    "evaluate_horizon('target_5d')\n",
    "evaluate_horizon('target_10d')\n",
    "evaluate_horizon('target_20d')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
