{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b70fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /opt/anaconda3/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->vaderSentiment) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d20ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8865d321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81803, 19),\n",
       "   ticker        date                created_at  \\\n",
       " 0     VZ  2014-01-05 2014-01-05 20:12:05+00:00   \n",
       " 1     VZ  2014-01-15 2014-01-15 09:28:46+00:00   \n",
       " 2      T  2014-01-15 2014-01-15 09:28:46+00:00   \n",
       " 3     VZ  2014-01-21 2014-01-21 17:04:22+00:00   \n",
       " 4    IBM  2014-01-21 2014-01-21 15:24:20+00:00   \n",
       " \n",
       "                                           clean_text  \\\n",
       " 0                 the s amp ps worst sectors in 2013   \n",
       " 1  ahah had to search ticker as well after i saw ...   \n",
       " 2  ahah had to search ticker as well after i saw ...   \n",
       " 3  sorry t mobile verizon is still the mightiest ...   \n",
       " 4  hoy reportaran al cierre de mercado entre otra...   \n",
       " \n",
       "                                            base_text  user.followers_count  \\\n",
       " 0  $VZ The S&amp;Ps Worst Sectors in 2013 http://...                     9   \n",
       " 1  @maoxian ahah had to search ticker as well aft...                  6069   \n",
       " 2  @maoxian ahah had to search ticker as well aft...                  6069   \n",
       " 3  $VZ - Sorry T-Mobile, Verizon Is Still the Mig...                  1461   \n",
       " 4  Hoy reportaran al cierre de mercado $IBM, $TXN...                  1073   \n",
       " \n",
       "    followers  has_event_word       open       high        low      close  \\\n",
       " 0          9            True        NaN        NaN        NaN        NaN   \n",
       " 1       6069           False  47.349998  48.380001  47.279999  48.270000   \n",
       " 2       6069           False  33.660000  34.000000  33.549999  33.790001   \n",
       " 3       1461           False  48.840000  48.900002  46.759998  47.700001   \n",
       " 4       1073            True        NaN        NaN        NaN        NaN   \n",
       " \n",
       "    adj_close      volume  daily_return    ret_1d    ret_3d    ret_5d    ret_7d  \n",
       " 0        NaN         NaN           NaN       NaN       NaN       NaN       NaN  \n",
       " 1  41.126583  21722300.0      0.025276  0.005386 -0.011809 -0.008494 -0.012016  \n",
       " 2  28.203867  25786400.0      0.009260  0.005031 -0.006511  0.000296 -0.008287  \n",
       " 3  40.640934  33165500.0     -0.013444 -0.007757 -0.001467 -0.007128 -0.001467  \n",
       " 4        NaN         NaN           NaN       NaN       NaN       NaN       NaN  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"merged_dataset.pkl\") \n",
    "\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22e3a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34851, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "\n",
    "# Drop rows without returns (if any)\n",
    "df = df.dropna(subset=[\"daily_return\", \"ret_3d\", \"ret_5d\", \"ret_7d\"])\n",
    "\n",
    "# Sort for later EWMA\n",
    "df = df.sort_values([\"ticker\", \"date\", \"created_at\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d86029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34851.000000\n",
       "mean         0.107053\n",
       "std          0.302995\n",
       "min         -0.922500\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.318200\n",
       "max          0.953800\n",
       "Name: sent_raw, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"sent_raw\"] = df[\"clean_text\"].astype(str).apply(\n",
    "    lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "df[\"sent_raw\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfb7d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/ddjwhrn11vn435ndqk2yyjnc0000gn/T/ipykernel_24861/3220833839.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(agg_group)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11177, 10),\n",
       "   ticker        date  sent_raw  sent_weighted  followers_mean  tweet_count  \\\n",
       " 0   AAPL  2014-01-02  0.103657       0.072854     1182.571429          7.0   \n",
       " 1   AAPL  2014-01-03  0.159500      -0.038990     4002.333333          3.0   \n",
       " 2   AAPL  2014-01-06  0.079844       0.012992     9452.555556          9.0   \n",
       " 3   AAPL  2014-01-07  0.354350       0.455834     3946.500000         14.0   \n",
       " 4   AAPL  2014-01-08  0.281275       0.279246     6444.500000          4.0   \n",
       " \n",
       "    daily_return    ret_3d    ret_5d    ret_7d  \n",
       " 0     -0.014064 -0.023665 -0.030029 -0.031457  \n",
       " 1     -0.021966  0.004584 -0.014862  0.010000  \n",
       " 2      0.005453 -0.013623 -0.015075  0.024691  \n",
       " 3     -0.007151 -0.013147  0.011758  0.026313  \n",
       " 4      0.006333 -0.014224  0.025577 -0.005134  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agg_group(g):\n",
    "    w = g[\"user.followers_count\"].fillna(0).clip(lower=1)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"sent_raw\": g[\"sent_raw\"].mean(),\n",
    "        \"sent_weighted\": (g[\"sent_raw\"] * w).sum() / w.sum(),\n",
    "        \"followers_mean\": g[\"user.followers_count\"].mean(),\n",
    "        \"tweet_count\": len(g),\n",
    "        \"daily_return\": g[\"daily_return\"].iloc[0],\n",
    "        \"ret_3d\": g[\"ret_3d\"].iloc[0],\n",
    "        \"ret_5d\": g[\"ret_5d\"].iloc[0],\n",
    "        \"ret_7d\": g[\"ret_7d\"].iloc[0],\n",
    "    })\n",
    "\n",
    "daily = (\n",
    "    df\n",
    "    .groupby([\"ticker\", \"date\"], as_index=False)\n",
    "    .apply(agg_group)\n",
    ")\n",
    "\n",
    "daily = daily.reset_index(drop=True)\n",
    "daily.shape, daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12270c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>sent_raw</th>\n",
       "      <th>sent_weighted</th>\n",
       "      <th>followers_mean</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>ret_3d</th>\n",
       "      <th>ret_5d</th>\n",
       "      <th>ret_7d</th>\n",
       "      <th>sent_ewma_2</th>\n",
       "      <th>sent_ewma_5</th>\n",
       "      <th>sent_ewma_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>0.103657</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>1182.571429</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>-0.031457</td>\n",
       "      <td>0.103657</td>\n",
       "      <td>0.103657</td>\n",
       "      <td>0.103657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>-0.038990</td>\n",
       "      <td>4002.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>-0.014862</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.140886</td>\n",
       "      <td>0.122271</td>\n",
       "      <td>0.113810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>0.079844</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>9452.555556</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.013623</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.100192</td>\n",
       "      <td>0.108129</td>\n",
       "      <td>0.107635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>0.354350</td>\n",
       "      <td>0.455834</td>\n",
       "      <td>3946.500000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.007151</td>\n",
       "      <td>-0.013147</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.026313</td>\n",
       "      <td>0.269631</td>\n",
       "      <td>0.190203</td>\n",
       "      <td>0.152492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>0.281275</td>\n",
       "      <td>0.279246</td>\n",
       "      <td>6444.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>-0.014224</td>\n",
       "      <td>0.025577</td>\n",
       "      <td>-0.005134</td>\n",
       "      <td>0.277394</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.175907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date  sent_raw  sent_weighted  followers_mean  tweet_count  \\\n",
       "0   AAPL  2014-01-02  0.103657       0.072854     1182.571429          7.0   \n",
       "1   AAPL  2014-01-03  0.159500      -0.038990     4002.333333          3.0   \n",
       "2   AAPL  2014-01-06  0.079844       0.012992     9452.555556          9.0   \n",
       "3   AAPL  2014-01-07  0.354350       0.455834     3946.500000         14.0   \n",
       "4   AAPL  2014-01-08  0.281275       0.279246     6444.500000          4.0   \n",
       "\n",
       "   daily_return    ret_3d    ret_5d    ret_7d  sent_ewma_2  sent_ewma_5  \\\n",
       "0     -0.014064 -0.023665 -0.030029 -0.031457     0.103657     0.103657   \n",
       "1     -0.021966  0.004584 -0.014862  0.010000     0.140886     0.122271   \n",
       "2      0.005453 -0.013623 -0.015075  0.024691     0.100192     0.108129   \n",
       "3     -0.007151 -0.013147  0.011758  0.026313     0.269631     0.190203   \n",
       "4      0.006333 -0.014224  0.025577 -0.005134     0.277394     0.220560   \n",
       "\n",
       "   sent_ewma_10  \n",
       "0      0.103657  \n",
       "1      0.113810  \n",
       "2      0.107635  \n",
       "3      0.152492  \n",
       "4      0.175907  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily = daily.sort_values([\"ticker\", \"date\"])\n",
    "\n",
    "for span in [2, 5, 10]:\n",
    "    daily[f\"sent_ewma_{span}\"] = (\n",
    "        daily\n",
    "        .groupby(\"ticker\")[\"sent_raw\"]\n",
    "        .transform(lambda s: s.ewm(span=span, adjust=False).mean())\n",
    "    )\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f232c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11177, 13),\n",
       "   ticker        date  sent_raw  sent_weighted  sent_ewma_2  sent_ewma_5  \\\n",
       " 0   AAPL  2014-01-02  0.103657       0.072854     0.103657     0.103657   \n",
       " 1   AAPL  2014-01-03  0.159500      -0.038990     0.140886     0.122271   \n",
       " 2   AAPL  2014-01-06  0.079844       0.012992     0.100192     0.108129   \n",
       " 3   AAPL  2014-01-07  0.354350       0.455834     0.269631     0.190203   \n",
       " 4   AAPL  2014-01-08  0.281275       0.279246     0.277394     0.220560   \n",
       " \n",
       "    sent_ewma_10  followers_mean  tweet_count  daily_return    ret_3d  \\\n",
       " 0      0.103657     1182.571429          7.0     -0.014064 -0.023665   \n",
       " 1      0.113810     4002.333333          3.0     -0.021966  0.004584   \n",
       " 2      0.107635     9452.555556          9.0      0.005453 -0.013623   \n",
       " 3      0.152492     3946.500000         14.0     -0.007151 -0.013147   \n",
       " 4      0.175907     6444.500000          4.0      0.006333 -0.014224   \n",
       " \n",
       "      ret_5d    ret_7d  \n",
       " 0 -0.030029 -0.031457  \n",
       " 1 -0.014862  0.010000  \n",
       " 2 -0.015075  0.024691  \n",
       " 3  0.011758  0.026313  \n",
       " 4  0.025577 -0.005134  )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = \"ret_5d\"\n",
    "\n",
    "ml = daily.dropna(subset=[target_col]).copy()\n",
    "\n",
    "feature_cols = [\n",
    "    \"sent_raw\",\n",
    "    \"sent_weighted\",\n",
    "    \"sent_ewma_2\",\n",
    "    \"sent_ewma_5\",\n",
    "    \"sent_ewma_10\",\n",
    "    \"followers_mean\",\n",
    "    \"tweet_count\",\n",
    "]\n",
    "\n",
    "ml = ml[[\"ticker\", \"date\"] + feature_cols + [\"daily_return\", \"ret_3d\", \"ret_5d\", \"ret_7d\"]]\n",
    "ml.shape, ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd97ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.to_csv(\"ml_dataset_high_impact.csv\", index=False)\n",
    "ml.to_pickle(\"ml_dataset_high_impact.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
